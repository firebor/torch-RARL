!!python/object/apply:collections.OrderedDict
- - - N_mu
    - 5.0
  - - N_nu
    - 1.0
  - - adv_fraction
    - 2.5
  - - adversary_kwargs
    - dict(batch_size=512, gamma=0.999, learning_rate=0.02250803339759749, n_critic_updates=5,
      cg_max_steps=10, target_kl=0.02, gae_lambda=0.92 )
  - - adversary_policy
    - MlpPolicy
  - - adversary_policy_kwargs
    - dict( activation_fn=torch.nn.ReLU, net_arch=[dict(pi=[64, 64], vf=[64, 64])]
      )
  - - device
    - cuda:0
  - - n_envs
    - 1
  - - n_steps_adversary
    - 128
  - - n_steps_protagonist
    - 2048
  - - n_timesteps
    - 5000000.0
  - - normalize
    - true
  - - protagonist_kwargs
    - dict(batch_size=128, gamma=0.95, learning_rate=1.3706859653339884e-05, n_critic_updates=30,
      cg_max_steps=25, target_kl=0.01, gae_lambda=0.9 )
  - - protagonist_policy
    - MlpPolicy
  - - protagonist_policy_kwargs
    - dict( activation_fn=torch.nn.ReLU, net_arch=[dict(pi=[256, 256], vf=[256, 256])]
      )
