!!python/object/apply:collections.OrderedDict
- - - N_mu
    - 10.0
  - - N_nu
    - 10.0
  - - adv_fraction
    - 1.0
  - - adversary_kwargs
    - dict(batch_size=64, gamma=0.99, learning_rate=2.5e-4, n_critic_updates=10, cg_max_steps=15,
      target_kl=0.01, gae_lambda=0.95 )
  - - adversary_policy
    - MlpPolicy
  - - adversary_policy_kwargs
    - dict( activation_fn=torch.nn.Tanh, net_arch=[dict(pi=[64, 64], vf=[64, 64])]
      )
  - - device
    - cuda:0
  - - n_envs
    - 16
  - - n_steps_adversary
    - 128
  - - n_steps_protagonist
    - 2048
  - - n_timesteps
    - 5000000.0
  - - normalize
    - true
  - - protagonist_kwargs
    - dict(batch_size=64, gamma=0.99, learning_rate=2.5e-4, n_critic_updates=10, cg_max_steps=15,
      target_kl=0.01, gae_lambda=0.95 )
  - - protagonist_policy
    - MlpPolicy
  - - protagonist_policy_kwargs
    - dict( activation_fn=torch.nn.Tanh, net_arch=[dict(pi=[64, 64], vf=[64, 64])]
      )
